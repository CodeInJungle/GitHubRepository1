install.packages("car")
install.packages("car")
install.packages("car")
install.packages("car")
install.packages("car")
install.packages("car")
library(car)
data.c <- read.csv("C:/Users/vsure/SharePoint/ES ADM Actionable Analytics - Docum/Training/EDA/EDA-102/titanic.csv", na.strings="", stringsAsFactors=FALSE, header=F)
View(data.c)
View(data.c)
utils:::menuInstallPkgs()
q()
install.packages("forecast")
library("forecast")
rain <- scan("http://robjhyndman.com/tsdldata/hurst/precip1.dat",skip=1)
rainseries <- ts(rain,start=c(1813))
plot.ts(rainseries)
rainseriesforecasts <- HoltWinters(rainseries, beta=FALSE, gamma=FALSE)
rainseriesforecasts
rainseriesforecasts$fitted
plot(rainseriesforecasts)
rainseriesforecasts2 <- forecast.HoltWinters(rainseriesforecasts, h=8)
plot.forecast(rainseriesforecasts2)
rainseriesforecasts2
View(rainseriesforecasts)
View(as.data.fram(rainseriesforecasts))
View(as.data.frame(rainseriesforecasts))
View(as.data.frame(rainseriesforecasts2))
rainseriesforecasts <- HoltWinters(rainseries, beta=FALSE, gamma=FALSE)
rainseriesforecasts
View(rainseries)
rainseriesforecasts$fitted
acf(rainseriesforecasts2$residuals, lag.max=20)
Box.test(rainseriesforecasts2$residuals, lag=20, type="Ljung-Box")
plot.ts(rainseriesforecasts2$residuals)
qqnorm(rainseriesforecasts2$residuals, ylab = "Q-Q Plot of residuals")
QPData <- read.csv("C:/Users/vsure/Google Drive/Analytics (1)/DataSources/ProdAProdBData.csv", na.strings="", stringsAsFactors=FALSE,header=T)
View(QPData)
QPData <- read.csv("C:/Users/vsure/Google Drive/Analytics (1)/DataSources/ProdAProdBData.csv", na.strings="", stringsAsFactors=FALSE,header=T)
head(QPData)
plot(QPData)
str(QPData)
QPData$PriceA = as.integer(QPData$PriceA)
head(QPData)
QPData <- read.csv("C:/Users/vsure/Google Drive/Analytics (1)/DataSources/ProdAProdBData.csv", na.strings="", stringsAsFactors=FALSE,header=T)
str(QPData)
QPData$PriceA = as.integer(QPData$PriceA)
head(QPData)
QPData <- read.csv("C:/Users/vsure/Google Drive/Analytics (1)/DataSources/ProdAProdBData.csv", na.strings="", stringsAsFactors=FALSE,header=T)
str(QPData)
plot(QPData[[,2:6]])
plot(QPData)
QPData <- read.csv("C:/Users/vsure/Google Drive/Analytics (1)/DataSources/ProdAProdBData.csv", na.strings="", stringsAsFactors=FALSE,header=T)
plot(QPData)
library(memisc)
str(QPData)
m1 <- lm(QuantityA=PriceA~Promo2,data=QPData)
m1 <- lm(QuantityA=PriceA~Promo2,data=QPData)
mtable(m1)
log(2)
m1 = lm(log(Quantity)~log(PriceA)+log(PriceB)+Promo1+Promo2+Promo1*log(PriceA)+Promo2*log(PriceB),data=QPData)
head(QPData)
m1 = lm(log(QuantityA)~log(PriceA)+log(PriceB)+Promo1+Promo2+Promo1*log(PriceA)+Promo2*log(PriceB),data=QPData)
summary(m1)
View(QPData)
library(Hmisc)
describe(QPData)
summary(m1)
m2 = lm(log(QuantityA)~log(PriceA)+,data=QPData)
m2 = lm(log(QuantityA)~log(PriceA),data=QPData)
summary(m1)
summary(m2)
XC<-c(643,655,702,676,693)
XL<-c(484,456,402,411,439)
XM<-c(469,427,525,431,527)
XC<-matrix(XC,ncol=1)
XM<-matrix(XM,ncol=1)
XL<-matrix(XL,ncol=1)
safety<-rbind(XC,XM,XL)
safety
code1<-rep(1:3, each=5)
code1<-as.factor(code1)
cars_ex<-cbind(safety,code1)
# equality of variance test (LeveneF test)
library(s20x)
library("s20x")
install.packages("s20x")
library(s20x)
levene.test(cars_ex[,1]~code1,cars_ex,show.table=T)
cars_ex = as.data.frame(cars_ex)
levene.test(cars_ex[,1]~code1,cars_ex,show.table=T)
cars_ex
testC=aov(cars_ex[,1]~code1)
testC
summary(testC)
testC=aov(cars_ex[,1]~code1)
summary(testC)
head(cars_ex)
?aov
testC=aov(cars_ex[,1]~cars_ex[,2])
testC
summary(testC)
# pairwsie bonferroni correction
pair_car = pairwise.t.test(cars_ex[,1],cars_ex[,2],p.adj="bonf")
summary(pair_car)
pair_car = pairwise.t.test(cars_ex[,1],code1,p.adj="bonf")
summary(pair_car)
install.packages("boot")
library(boot)
hsb2<-read.table("http://www.ats.ucla.edu/stat/data/hsb2.csv", sep=",", header=T)
hsb2<-read.table("http://www.ats.ucla.edu/stat/data/hsb2.csv", sep=",", header=T)
View(hsb2)
View(hsb2)
test = aov(hsb2$write~hsb2$ses)
test
summary(test)
attach(hsb2)
tapply(write,ses,mean)
detach(hsb2)
pairwise_bonf = pairwise.t.test(write,as.factor(ses),p.adj="bonf")
attach(hsb2)
pairwise_bonf = pairwise.t.test(write,ses),p.adj="bonf")
pairwise_bonf = pairwise.t.test(write,ses,p.adj="bonf")
summary(pairwise_bonf)
pairwise_bonf
levene.test(write~ses,hsb2,show.table=T)
pairwise_bonf
class(hsb2)
str(hsb2)
hsb2$ses = as.factor(hsb2$ses)
str(hsb2)
test = aov(hsb2$write~hsb2$ses)
test
summary(test)
getwd()
#read inline data set
tb = read.table(header=TRUE,
text="
employee_2    19   23   18   22   23   29   25
employee_5    25   25   26   31   24   36   37
employee_7     0    4    2    2    3    4    2
employee_9    19   22   22   19   25   24   23
employee_12   13   13   20   17   12   22   20
employee_11   29   27   23   25   29   30   17
employee_16   32   35   31   35   24   25   36
employee_19    0    1   11    6    0    4   11
employee_17    7   17    9   12   13    6   12
employee_21    6   15   15   10    9    7   18
employee_24    5    8    0    1    6    3    1
employee_25    2    7    5    3    1    5    5
employee_27   17   15   17   23   23   17   22
employee_28   26   32   33   30   33   28   26
employee_29   27   29   24   29   26   31   28
employee_33    6    5   12    5   17   17    4
employee_36   32   26   20   23   24   25   21
employee_38    6   10   11    6    6    2    5
employee_39   30   37   32   35   37   41   42
employee_42   28   29   30   19   21   19   26
employee_43    6    8    6    7   17   11   14
employee_45    6   10   17   18   13   10    7
employee_46   18   19   22   17   21   15   23
employee_49    6   15   15   15   10   14    2
employee_50   30   28   29   31   24   20   25")
#find number of employees that are having more than 25 views or less than 5 views in day2
tb
a = c(2:5)
a
class(a)
l = c(TRUE,FALSE)
L
l
c = c("a","b")
c
class(c)
cbind
?cbind
cbind(0,1)
cbind(0,1,2,3)
cbind(0,rbind(1,1:3))
rbind(1,1:3)
rbind(1:3)
rbind(1:5)
rbind(4,1:5)
rbind(4,1:5,1:3)
rbind(4,1:5,5:10)
rbind(4,1:5,5:9)
cbind(1,11:15)
rbind(1,11:15)
cbind(1,rbind(1,11:15))
rbind(1,11:15)
cbind(1,rbind(2,11:15))
cbind(1:2,rbind(2,11:15))
cbind(1:length(c),c)
c = rbind(2,11:15)
cbind(1:length(c),c)
cbind(1:2,c)
nrow(c)
cbind(1:nrow(c),c)
str(cbind(1,3))
str(cbind(1,rbind(2,3)))
cbind(1,rbind(2,3))
d = data.frame(a,b,c)
dim(d)
a = c(1,2,3)
b = c(1,1)
c = c(2,3)
d = data.frame(a,b,c)
a = c(1,2)
b = c(1,1)
c = c(2,3)
d = data.frame(a,b,c)
dim(d)
length(d)
length(d)
str(d)
b = c("a","b")
d = data.frame(a,b,c)
dim(d)
length(d)
str(d)
a = c(1:100)
rand = sample(1:10,5)
rand
rand = sample(1:10,100)
rand = sample(1:10,100, replace = T)
rand
length(rand)
hist(rand)
y <- ts(x, frequency=7)
z <- fourier(ts(x, frequency=365.25), K=5)
zf <- fourierf(ts(x, frequency=365.25), K=5, h=100)
fit <- auto.arima(y, xreg=cbind(z,holiday), seasonal=FALSE)
fc <- forecast(fit, xreg=cbind(zf,holidayf), h=100)
x = sample(1,10,100,replace=T)
y <- ts(x, frequency=7)
z <- fourier(ts(x, frequency=365.25), K=5)
?fourier
library(forecast)
z <- fourier(ts(x, frequency=365.25), K=5)
zf <- fourierf(ts(x, frequency=365.25), K=5, h=100)
fit <- auto.arima(y, xreg=cbind(z,holiday), seasonal=FALSE)
fc <- forecast(fit, xreg=cbind(zf,holidayf), h=100)
holiday
library(lubridate)
ymd("2015-06-30")
0/0
x = rep(0/0, times = 10)
x
x == NaN
is.na(x)
a = c("uma","suresh","jaya","meera")
a
a[3]
a[3:4]
3:4
a[c(3,4)]
c(3,4)
3:4
3:100
seq(3,100)
?seq
seq(1,100,by =2)
y = c(-1,-3,0,1,2,5)
y > 0
y[y>0]
y = c(-1,-3,0,1,2,5,NA)
y
y>0
y[NA]
y[y>0]
list = list ("a",c(1,2),1:10)
list
list[[1]]
x = c(1,2,3)
y = 1
x + y
a
x = 1:100
x
x > 50
x[x>50]
q()
xor(!isTRUE(TRUE), 6 > -1)
q()
"%p%" <- function(left,right){ # Remember to add arguments!
cat(left,right)
}
"Good" %p% "job!"
paste("Hello","World!")
cat("Hello","World!")
class(paste("Hello","World!"))
class(cat("Hello","World!"))
cat?
?cat
?cat
squareOrCube = function(x){
if (x < 5) x^2
else x^3
}
squareOrCube(2)
squareOrCube(3)
squareOrCube(5)
squareOrCube = function(x){
if (x < 5) x^2
else "fool"
}
squareOrCube(5)
squareOrCube = function(x){
if (x < 5) x^2
else "fool"
}
squareOrCube(5)
squareOrCube = function(x){
if (x < 5) x^2
else "fool"
}
library("swirl")
swirl()
head(flags)
dim(flags)
viewinfo()
class(flags)
cls_list <- lapply(flags,class)
cls_list
class(cls_list)
as.character(cls_list)
cls_list <- sapply(flags,class)
cls_vect <- sapply(flags,class)
class(cls_vect)
sum(flags$orange)
flag_colors <- flags[,11:17]
head(flag_colors)
lapply(flag_colors,sum)
sapply(flag_colors,sum)
sapply(flag_colors,mean)
flag_shapes = flags[,19:23]
flag_shapes <- flags[,19:23]
lapply(flag_shapes, range)
shape_mat <- sapply(flag_shapes, range)
shape_mat
class(shape_mat)
unique(c(3,4,5,5,5,6,6,))
unique(c(3,4,5,5,5,6,6))
unique_vals = lapply(flags,unique)
unique_vals <- lapply(flags,unique)
unique_vals
sapply(unique_vals,length)
sapply(flags,unique)
lapply(unique_vals,function(elem) elem[2])
undebug(ls)
help ("<<-")
makeVector <- function(x = numeric()) {
m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setmean <- function(mean) m <<- mean
getmean <- function() m
list(set = set, get = get,
setmean = setmean,
getmean = getmean)
}
## Put comments here that give an overall description of what your
## functions do
## Write a short comment describing this function
makeCacheMatrix <- function(x = matrix()) {
m <- null
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function()x
setinverse <- function(inverse) m <<- inverse
getinverse <- function() m
list (set = set, get = get,
setinverse = setinverse,
getinverse = getinverse)
}
## Write a short comment describing this function
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
m <- x$getinverse()
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- solve(data,...)
m
}
m = matrix(1:4,2,3)
?matrix
m = matrix(1:4,nrow=2,ncol = 3)
m = matrix(1:6,nrow=2,ncol = 3)
m
data = rnorm(6)
m = matrix(data,nrow=2,ncol = 3)
cacheSolve(m)
cacheSolve(makeCacheMatrix,m)
mc = makeCacheMatrix(m)
m = matrix(data,nrow=2,ncol = 3)
mc = makeCacheMatrix(m)
## Write a short comment describing this function
makeCacheMatrix <- function(x = matrix()) {
m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function()x
setinverse <- function(inverse) m <<- inverse
getinverse <- function() m
list (set = set, get = get,
setinverse = setinverse,
getinverse = getinverse)
}
## Write a short comment describing this function
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
m <- x$getinverse()
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- solve(data,...)
m
}
data = rnorm(6)
m = matrix(data,nrow=2,ncol = 3)
mc = makeCacheMatrix(m)
cacheSolve(mc,m)
data = rnorm(9)
m = matrix(data,nrow=3,ncol = 3)
mc = makeCacheMatrix(m)
cacheSolve(mc,m)
?"%p"
?%
?%%
?%p%
.9/(1+.12-.9)
library(rJava)
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre1.8.0_77')
library(rJava)
install.packages('rJava')
library(rJava)
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre1.8.0_77')
library(rJava)
R.version.string
install_from_swirl("Getting and Cleaning Data")
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf = read.csv(path2csv,stringsAsFactors = FALSE)
mydf <- read.csv(path2csv,stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
?tbl_df
cran
?select
select(cran,ip_id,package,country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran,-time)
select(cran,-5:20)
-5:20
-(5:20)
cran
select(cran,-(X:size))
filter(cran,package == "swirl")
filter(cran,r_version=="3.1.1",country == "US")
?Comparison
filter(cran,r_version=="3.1.1",country == "IN")
filter(cran,r_version<="3.1.1",country == "IN")
filter(cran,r_version<="3.0.2",country == "IN")
filter(cran,country == "US"|country == "IN")
filter(cran,size>100500,r_os == "linux-gnu")
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran,!is.na(r_version))
cran2 = select(cran,ip_id:store)
cran2 = select(cran,size:ip_id)
cran2 <- select(cran,size:ip_id)
arrange(cran2,ip_id)
arrange(cran,desc(ip_id))
arrange(cran2,desc(ip_id))
arrange(cran2,package,ip_id)
arrange(cran2,country,desc(r_version),ip_id)
cran3 <- select(cran,ip_id,package,size)
cran3
mutate(cran3,size_mb=size/2^20)
mutate(cran3,size_mb=size/2^20,size_gb=size_mb/2^10)
mutate(cran3,correct_size=size+1000)
summarize(cran,avg_bytes = mean(size))
require(knitr)
require(markdown)
setwd("C:/Main/Projects/GitHub")
